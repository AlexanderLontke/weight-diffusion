{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at tbs17/MathBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1045, 2066, 3616,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[ 101, 1045, 2066, 2028, 2048, 2093,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('tbs17/MathBERT', output_hidden_states=True)\n",
    "model = BertModel.from_pretrained(\"tbs17/MathBERT\")\n",
    "text = \"I like numbers\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "print(encoded_input)\n",
    "text = \"I like one two three\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "print(encoded_input)\n",
    "#output = model(encoded_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train_loss\": -999, \"train_acc\": -999, \"validation_loss\": 2.6630959510803223, \"validation_acc\": 0.1038, \"test_loss\": 2.6806106567382812, \"test_acc\": 0.101, \"done\": false, \"timesteps_total\": null, \"episodes_total\": null, \"training_iteration\": 0, \"experiment_id\": \"d02450c8cf854c6092fe7d93bfb6499c\", \"date\": \"2021-07-01_17-22-51\", \"timestamp\": 1625160171, \"time_this_iter_s\": 26.644359350204468, \"time_total_s\": 26.644359350204468, \"pid\": 7141, \"hostname\": \"e293b6fd43a8\", \"node_ip\": \"172.17.0.16\", \"config\": {\"model::type\": \"CNN\", \"model::channels_in\": 1, \"model::o_dim\": 4, \"model::nlin\": \"tanh\", \"model::dropout\": 0.0, \"model::init_type\": \"uniform\", \"model::use_bias\": false, \"optim::optimizer\": \"adam\", \"optim::lr\": 0.0003, \"optim::wd\": 0.0, \"seed\": 13, \"training::batchsize\": 10, \"training::epochs_train\": 50, \"training::start_epoch\": 1, \"training::output_epoch\": 1, \"training::val_epochs\": 1, \"training::idx_out\": 500, \"training::checkpoint_dir\": null, \"cuda\": false, \"dataset::dump\": \"/netscratch/dtaskiran/zoos/MNIST/tune_zoo_mnist_uniform/dataset.pt\", \"wandb\": {\"project\": \"MNIST Uniform\", \"api_key_file\": \"/netscratch/dtaskiran/wandb/wandb.key\", \"log_config\": false}}, \"time_since_restore\": 26.644359350204468, \"timesteps_since_restore\": 0, \"iterations_since_restore\": 1, \"trial_id\": \"c0371_00012\"}\n",
      "\n",
      "{'train_loss': -999, 'train_acc': -999, 'validation_loss': 2.6630959510803223, 'validation_acc': 0.1038, 'test_loss': 2.6806106567382812, 'test_acc': 0.101, 'done': False, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 0, 'experiment_id': 'd02450c8cf854c6092fe7d93bfb6499c', 'date': '2021-07-01_17-22-51', 'timestamp': 1625160171, 'time_this_iter_s': 26.644359350204468, 'time_total_s': 26.644359350204468, 'pid': 7141, 'hostname': 'e293b6fd43a8', 'node_ip': '172.17.0.16', 'config': {'model::type': 'CNN', 'model::channels_in': 1, 'model::o_dim': 4, 'model::nlin': 'tanh', 'model::dropout': 0.0, 'model::init_type': 'uniform', 'model::use_bias': False, 'optim::optimizer': 'adam', 'optim::lr': 0.0003, 'optim::wd': 0.0, 'seed': 13, 'training::batchsize': 10, 'training::epochs_train': 50, 'training::start_epoch': 1, 'training::output_epoch': 1, 'training::val_epochs': 1, 'training::idx_out': 500, 'training::checkpoint_dir': None, 'cuda': False, 'dataset::dump': '/netscratch/dtaskiran/zoos/MNIST/tune_zoo_mnist_uniform/dataset.pt', 'wandb': {'project': 'MNIST Uniform', 'api_key_file': '/netscratch/dtaskiran/wandb/wandb.key', 'log_config': False}}, 'time_since_restore': 26.644359350204468, 'timesteps_since_restore': 0, 'iterations_since_restore': 1, 'trial_id': 'c0371_00012'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open ('./../data/tune_zoo_mnist_uniform/NN_tune_trainable_c0371_00012_12_seed=13_2021-07-01_17-22-16/result.json', 'r') as f:\n",
    "  line = f.readline()\n",
    "  print(line)\n",
    "  data = json.loads(line)\n",
    "\n",
    "# Output: {'name': 'Bob', 'languages': ['English', 'French']}\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training loss is -999. The training accuracy is -999. The validation loss is 2.663. The validation accuracy is 0.1038. The test loss is 2.681. The test accuracy is 0.101. \n"
     ]
    }
   ],
   "source": [
    "mystring = f\"The training loss is {data['train_loss']:.4g}. \" \\\n",
    "           f\"The training accuracy is {data['train_acc']:.4g}. \" \\\n",
    "           f\"The validation loss is {data['validation_loss']:.4g}. \" \\\n",
    "           f\"The validation accuracy is {data['validation_acc']:.4g}. \" \\\n",
    "           f\"The test loss is {data['test_loss']:.4g}. \" \\\n",
    "           f\"The test accuracy is {data['test_acc']:.4g}. \"\n",
    "print(mystring)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
