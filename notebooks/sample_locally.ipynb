{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import yaml\n",
    "import pickle\n",
    "\n",
    "from weight_diffusion.data.data_utils.helper import perform_train_test_validation_split\n",
    "from weight_diffusion.data.modelzoo_with_latent_dataset import ModelZooWithLatentDataset\n",
    "from weight_diffusion.ofga.sampling import sample_from_prompt\n",
    "from weight_diffusion.data.modelzoo_dataset import get_all_directories_for_a_path\n",
    "from weight_diffusion.execution.util import load_model_from_config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "test_models = perform_train_test_validation_split(\n",
    "    list_to_split=get_all_directories_for_a_path(\"/Users/alexanderlontke/Documents/Uni/St. Gallen/HS_22_23/integrative_master_project/data/tune_zoo_mnist_uniform\"),\n",
    "    dataset_split_ratios=[7,3],\n",
    "    split=\"test\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init attn encoder\n",
      "## encoder -- use index_dict\n",
      "model: use only positive contrast loss\n",
      "initialze projection head\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Models:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute 2 random permutations for layer 0 - 0\n",
      "compute 2 random permutations for layer 1 - 3\n",
      "compute 2 random permutations for layer 2 - 6\n",
      "compute 2 random permutations for layer 3 - 9\n",
      "prepared 10 permutations\n",
      "prepare permutation dicts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Models: 100%|██████████| 10/10 [00:05<00:00,  1.71it/s]\n",
      "Indexing dataset: 100%|██████████| 10/10 [00:00<00:00, 1873.04it/s]\n"
     ]
    }
   ],
   "source": [
    "config_path = \"/Users/alexanderlontke/Documents/Uni/St. Gallen/HS_22_23/integrative_master_project/weight-diffusion/configs/ldm/hp-ldm.yaml\"\n",
    "with open(config_path, \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "\n",
    "dataset = ModelZooWithLatentDataset(\n",
    "    data_dir=Path(\n",
    "        \"/Users/alexanderlontke/Documents/Uni/St. Gallen/HS_22_23/integrative_master_project/data/tune_zoo_mnist_uniform\"\n",
    "    ),\n",
    "    split=\"irrelevant\",\n",
    "    checkpoint_property_of_interest=\"test_acc\",\n",
    "    openai_coefficient=config[\"openai_coefficient\"],\n",
    "    number_of_permutations=10,\n",
    "    device=\"cpu\",\n",
    "    model_directory_paths=test_models[:10],\n",
    "    encoder_config=config[\"encoder_config\"],\n",
    "    tokenizer_config=config[\"tokenizer_config\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "prompts = [torch.Tensor([[*dataset[10 * (i*5)][\"prompt_latent\"]]]) for i in range(10)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /Users/alexanderlontke/Desktop/last.ckpt\n",
      "Global Step: 35680\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 387.94 M params.\n"
     ]
    }
   ],
   "source": [
    "model = load_model_from_config(\n",
    "    config=config,\n",
    "    ckpt=\"/Users/alexanderlontke/Desktop/last.ckpt\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderlontke/.conda/envs/weight-diffusion/lib/python3.10/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is torch.Size([1, 700]), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [02:08<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is torch.Size([1, 700]), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [02:08<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is torch.Size([1, 700]), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [02:07<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is torch.Size([1, 700]), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [02:04<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is torch.Size([1, 700]), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [02:05<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is torch.Size([1, 700]), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [02:04<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is torch.Size([1, 700]), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [01:56<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is torch.Size([1, 700]), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [01:57<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is torch.Size([1, 700]), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [01:58<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is torch.Size([1, 700]), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [01:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [16], line 13\u001B[0m\n\u001B[1;32m      4\u001B[0m     samples[\u001B[38;5;28mstr\u001B[39m(prompt)] \u001B[38;5;241m=\u001B[39m sample_from_prompt(\n\u001B[1;32m      5\u001B[0m         prompt\u001B[38;5;241m=\u001B[39mprompt,\n\u001B[1;32m      6\u001B[0m         sampling_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     10\u001B[0m         model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m     11\u001B[0m     )\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/Users/alexanderlontke/Desktop/ldm_samples.pkl\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[0;32m---> 13\u001B[0m     pickle\u001B[38;5;241m.\u001B[39mdump(samples, file\u001B[38;5;241m=\u001B[39mfile)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "shape = dataset[123][\"checkpoint_latent\"].shape\n",
    "samples = {}\n",
    "for prompt in prompts:\n",
    "    samples[str(prompt)] = sample_from_prompt(\n",
    "        prompt=prompt,\n",
    "        sampling_steps=50,\n",
    "        shape=shape,\n",
    "        guidance_scale=1.0,\n",
    "        uc=None,\n",
    "        model=model,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "with open(\"/Users/alexanderlontke/Desktop/ldm_samples.pkl\", \"wb\") as file:\n",
    "    pickle.dump(samples, file=file)\n",
    "# with open(\"/Users/alexanderlontke/Desktop/ldm_samples.pkl\", \"rb\") as input_file:\n",
    "#     loaded_samples = pickle.load(input_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run Evaluation ##"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sampled_weights = encoder.forward_decoder(sampled_weights_latent)\n",
    "print(\"################    WEIGHTS       ###############\")\n",
    "print(sampled_weights)\n",
    "print(\"################################################\")\n",
    "sampled_checkpoint = generate_checkpoints_from_weights(\n",
    "    sampled_weights, model_config, layer_list\n",
    ")\n",
    "sampled_mnist_model_checkpoints_dict[str(prompt)] = sampled_checkpoint\n",
    "# Return dictionary containing target metrics for each prompt\n",
    "targets_dict[str(prompt)] = prompt_statistics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}